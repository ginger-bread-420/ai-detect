{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "!pip install datasets tqdm transformers"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-o9pqoIZGKR1",
        "outputId": "e15dfbe7-d53c-473e-dce3-f24079fe5bdf"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting datasets\n",
            "  Downloading datasets-3.0.2-py3-none-any.whl.metadata (20 kB)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (4.66.5)\n",
            "Requirement already satisfied: transformers in /usr/local/lib/python3.10/dist-packages (4.44.2)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from datasets) (3.16.1)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.10/dist-packages (from datasets) (1.26.4)\n",
            "Requirement already satisfied: pyarrow>=15.0.0 in /usr/local/lib/python3.10/dist-packages (from datasets) (16.1.0)\n",
            "Collecting dill<0.3.9,>=0.3.0 (from datasets)\n",
            "  Downloading dill-0.3.8-py3-none-any.whl.metadata (10 kB)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.10/dist-packages (from datasets) (2.2.2)\n",
            "Requirement already satisfied: requests>=2.32.2 in /usr/local/lib/python3.10/dist-packages (from datasets) (2.32.3)\n",
            "Collecting xxhash (from datasets)\n",
            "  Downloading xxhash-3.5.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (12 kB)\n",
            "Collecting multiprocess<0.70.17 (from datasets)\n",
            "  Downloading multiprocess-0.70.16-py310-none-any.whl.metadata (7.2 kB)\n",
            "Requirement already satisfied: fsspec<=2024.9.0,>=2023.1.0 in /usr/local/lib/python3.10/dist-packages (from fsspec[http]<=2024.9.0,>=2023.1.0->datasets) (2024.6.1)\n",
            "Requirement already satisfied: aiohttp in /usr/local/lib/python3.10/dist-packages (from datasets) (3.10.10)\n",
            "Requirement already satisfied: huggingface-hub>=0.23.0 in /usr/local/lib/python3.10/dist-packages (from datasets) (0.24.7)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from datasets) (24.1)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from datasets) (6.0.2)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.10/dist-packages (from transformers) (2024.9.11)\n",
            "Requirement already satisfied: safetensors>=0.4.1 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.4.5)\n",
            "Requirement already satisfied: tokenizers<0.20,>=0.19 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.19.1)\n",
            "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (2.4.3)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (1.3.1)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (24.2.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (1.4.1)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (6.1.0)\n",
            "Requirement already satisfied: yarl<2.0,>=1.12.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (1.16.0)\n",
            "Requirement already satisfied: async-timeout<5.0,>=4.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (4.0.3)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.23.0->datasets) (4.12.2)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests>=2.32.2->datasets) (3.4.0)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests>=2.32.2->datasets) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests>=2.32.2->datasets) (2.2.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests>=2.32.2->datasets) (2024.8.30)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.10/dist-packages (from pandas->datasets) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas->datasets) (2024.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.10/dist-packages (from pandas->datasets) (2024.2)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.8.2->pandas->datasets) (1.16.0)\n",
            "Requirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.10/dist-packages (from yarl<2.0,>=1.12.0->aiohttp->datasets) (0.2.0)\n",
            "Downloading datasets-3.0.2-py3-none-any.whl (472 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m472.7/472.7 kB\u001b[0m \u001b[31m9.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading dill-0.3.8-py3-none-any.whl (116 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m116.3/116.3 kB\u001b[0m \u001b[31m9.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading multiprocess-0.70.16-py310-none-any.whl (134 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m134.8/134.8 kB\u001b[0m \u001b[31m8.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading xxhash-3.5.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (194 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m194.1/194.1 kB\u001b[0m \u001b[31m7.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: xxhash, dill, multiprocess, datasets\n",
            "Successfully installed datasets-3.0.2 dill-0.3.8 multiprocess-0.70.16 xxhash-3.5.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "from torch.utils.data import DataLoader, Dataset\n",
        "from torch import optim\n",
        "from transformers import AutoTokenizer, AutoModelForCausalLM\n",
        "from datasets import load_dataset\n",
        "from tqdm import tqdm\n",
        "\n",
        "\n",
        "from huggingface_hub import login\n",
        "login(token=\"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\", add_to_git_credential=True)\n",
        "access_token = \"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\"\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "r9yWGsCV-34Y",
        "outputId": "d654d318-1b05-4335-8613-9f6b25264ff3"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Token is valid (permission: fineGrained).\n",
            "Your token has been saved in your configured git credential helpers (store).\n",
            "Your token has been saved to /root/.cache/huggingface/token\n",
            "Login successful\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "dataset = pd.read_csv('/content/Training_Essay_Data.csv', quotechar='\"')\n",
        "class_0 = dataset[dataset['generated'] == 0]\n",
        "class_1 = dataset[dataset['generated'] == 1]\n",
        "balanced_class_0 = class_0.sample(n=500, random_state=42)\n",
        "balanced_class_1 = class_1.sample(n=500, random_state=42)\n",
        "balanced_dataset = pd.concat([balanced_class_0, balanced_class_1]).reset_index(drop=True)\n",
        "balanced_dataset = balanced_dataset.sample(frac=1, random_state=42).reset_index(drop=True)\n",
        "print(balanced_dataset['generated'].value_counts())\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CW9Kr2pZ4hTp",
        "outputId": "85bd720f-920f-4a02-90a4-3db6a9a1d9ba"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "generated\n",
            "1    11637\n",
            "0    11637\n",
            "Name: count, dtype: int64\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "dataset.head()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "vWo6FcpElUgT",
        "outputId": "7a4f6c9d-a89c-4e50-be98-e15d3d7a677a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                                                text  generated\n",
              "0  \\nCellphones are a pervasive technology in our...          1\n",
              "1  \\nWhen discussing the pros and cons of changin...          1\n",
              "2  This all started 21 years ago. Here is how the...          0\n",
              "3  Dear Mr. Senator,\\n\\nIt has come to my, as wel...          0\n",
              "4  Dear State Senator, Many people today have ver...          0"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-eff60904-fd73-4186-a065-2e7e7cd56380\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>text</th>\n",
              "      <th>generated</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>\\nCellphones are a pervasive technology in our...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>\\nWhen discussing the pros and cons of changin...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>This all started 21 years ago. Here is how the...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>Dear Mr. Senator,\\n\\nIt has come to my, as wel...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>Dear State Senator, Many people today have ver...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-eff60904-fd73-4186-a065-2e7e7cd56380')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-eff60904-fd73-4186-a065-2e7e7cd56380 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-eff60904-fd73-4186-a065-2e7e7cd56380');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-1a52f040-603e-4a64-b69c-b4a02237af7b\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-1a52f040-603e-4a64-b69c-b4a02237af7b')\"\n",
              "            title=\"Suggest charts\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-1a52f040-603e-4a64-b69c-b4a02237af7b button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "variable_name": "dataset",
              "summary": "{\n  \"name\": \"dataset\",\n  \"rows\": 23274,\n  \"fields\": [\n    {\n      \"column\": \"text\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 22251,\n        \"samples\": [\n          \"I believe that successful people try new things and take risks rather than only doing what they already know how to do well. I have seen many successful people in my life and they all seem to have a mix of experience and new ideas. They are not afraid to try something new and they are also not afraid to take risks.\\n\\nOne of the best examples of a successful person who takes risks is Steve Jobs. Steve Jobs was the co-founder of Apple and he was responsible for developing the iPhone and the iPad. He was also responsible for creating the Apple computer and he was also responsible for creating the iPod.\\n\\nSteve Jobs was not afraid to try something new and he was also not afraid to take risks. He was always willing to take risks and he was also always willing to experiment. He was also always willing to learn and he was always willing to grow.\\n\\nI think that this is a good thing because it allows successful people to learn and to grow. It also allows them to be creative and to be innovative. It also allows them to be successful.\\n\\nI also think that this is a good thing because it allows successful people to be risk-takers. They are not afraid to take risks and they are not afraid to experiment. They are also not afraid to learn and they are also not afraid to grow.\\n\\nI think that this is a good thing because it allows successful people to be successful. I think that it is important for successful people to try new things and to take risks. I think that it is important for successful people to be risk-takers and I think that it is important for successful people to be creative and to be innovative. I think that it is important for successful people to be successful.\\n\\n\",\n          \"In recent years, the power of technology and its impact on our lives has been increasingly undeniable. From smartphones to computers, this cutting-edge tech is rapidly changing not only our daily routines but also how we interact with one another. As such, one of the most powerful ways in which technology has impacted us is through online education. Online education can take many forms, ranging from fully online classes offered by universities and colleges to private lessons facilitated via Skype or Zoom. Whatever format it takes though, the advantages that it offers are unparalleled when compared to traditional learning methods; convenience being perhaps the biggest one. With an internet connection and access to a computer or other device \\u2013 like a tablet or smartphone \\u2013 anyone interested in pursuing an educational goal can do so regardless of location or time constraints. This opens up new possibilities for those unable to attend physical institutions due either to living far away from them or having obligations that prevent regular attendance such as work commitments, family responsibilities etc. Additionally, online education often comes at significantly lower costs than conventional studies since there's no need for students (or their parents) to invest money into transportation expenses associated with getting back-and-forth from campus every day - let alone the cost savings associated with textbooks and related materials which can be accessed digitally rather than purchased physically! Not only does this make higher education more accessible financially speaking; but it eliminates any potential worries about missing out on lectures should something come up last minute as digital formats allow for easier flexible scheduling options as well as recordings of missed sessions that can be reviewed afterwards if needed. Given all these advantages however; there are still some drawbacks associated with going down this route instead of attending physical classrooms. The lack of human interaction inherent in virtual environments may lead some people who benefit much more than others from interacting face-to-face while studying towards reduced academic performance levels if they're unable/unwilling adjust accordingly - although depending on preferred learning styles this could actually just prove beneficial even\\n\",\n          \"\\nDistance learning has some notable drawbacks compared to traditional classroom-based instruction. For example, distance learning may not allow for face-to-face interaction, making it difficult for teachers to provide feedback and support. Distance learning can also be less engaging for students, as it can lack the competition and collaboration seen in traditional classrooms.\\n\\nStudies have found that interpersonal interactions between teachers and students are important for learning. Communication, competition, and inspiration from teachers can all have a positive impact on student performance and engagement. Teachers can provide students one-on-one feedback to address areas of difficulty or confusion, as well as praise for a job well done. The presence of peers in the classroom creates an atmosphere of competition that encourages students to work harder. Finally, teachers can serve as a model of success and inspire students to reach their goals.\\n\\nWhile online courses do offer a more flexible learning option, they cannot replicate the communication, competition, and inspiration of a traditional classroom. Interaction with peers is limited and feedback from teachers can be delayed or difficult to understand. Furthermore, there may be less motivation to succeed as there is no sense of competition.\\n\\nAttending classes in person is an invaluable educational experience that offers communication, competition, and inspiration from teachers that distance learning cannot. Traditional classrooms provide students with the guidance and support they need to be successful, as well as an engaging learning environment that promotes engagement and independent learning.\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"generated\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0,\n        \"min\": 0,\n        \"max\": 1,\n        \"num_unique_values\": 2,\n        \"samples\": [\n          0,\n          1\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"
            }
          },
          "metadata": {},
          "execution_count": 81
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# Load the tokenizer and model\n",
        "model_name = \"meta-llama/Llama-3.2-1B-Instruct\"\n",
        "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
        "model = AutoModelForCausalLM.from_pretrained(model_name)\n",
        "\n",
        "# Set special tokens for padding\n",
        "tokenizer.pad_token = tokenizer.eos_token\n",
        "model.config.pad_token_id = model.config.eos_token_id\n",
        "\n",
        "model.to(device)\n",
        "\n",
        "# Generate response example\n",
        "@torch.no_grad()\n",
        "def generate_response(input_text):\n",
        "    model.eval()\n",
        "    input_ids = tokenizer.encode(input_text, return_tensors='pt').to(device)\n",
        "    output_ids = model.generate(input_ids, max_length=400, num_return_sequences=1, do_sample=True, pad_token_id=tokenizer.pad_token_id)\n",
        "    return tokenizer.decode(output_ids[0], skip_special_tokens=True)\n",
        "\n",
        "response = generate_response(\"write a news article about the impact on AI on Education system\")\n",
        "print(f\"Generated response: {response}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RR_ZT5awGCOV",
        "outputId": "c831768a-511f-4bd4-d163-9c05eb304303"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Generated response: write a news article about the impact on AI on Education system\n",
            "The rise of Artificial Intelligence (AI) has revolutionized numerous industries, including education. AI-powered tools and software are being used to personalize learning, automate grading, and enhance student engagement. However, the impact of AI on the education system is a topic of ongoing debate.\n",
            "\n",
            "One of the most significant effects of AI on education is the ability to personalize learning. AI-powered tools can analyze individual student data, identifying strengths and weaknesses, and providing tailored learning pathways. This can lead to improved academic outcomes, as students are able to learn at their own pace and focus on areas where they need the most support.\n",
            "\n",
            "Another area where AI is making a significant impact is in the realm of adaptive assessment. AI-powered tools can automatically adjust the difficulty level of quizzes and tests based on individual student performance, ensuring that students are held accountable for their own learning. This can help to reduce the stress and anxiety associated with high-stakes testing.\n",
            "\n",
            "However, the use of AI in education also raises concerns about the potential for bias and discrimination. AI algorithms can perpetuate existing biases and prejudices, leading to unequal treatment of certain groups of students. For example, AI-powered tools may be biased towards students from certain socio-economic backgrounds, or those with certain cultural or linguistic backgrounds.\n",
            "\n",
            "Moreover, the use of AI in education also raises concerns about the potential for job displacement. As AI takes over more routine and repetitive tasks, it may lead to job losses for educators and other professionals who are not directly involved in AI development.\n",
            "\n",
            "Despite these concerns, the use of AI in education is also having a positive impact on student outcomes. AI-powered tools can help to identify areas where students need additional support, and provide targeted interventions to help them succeed. For example, AI-powered speech-to-text tools can help students with learning disabilities to communicate more effectively, and AI-powered language learning tools can help students to improve their language skills.\n",
            "\n",
            "In conclusion, the impact of AI on the education system is\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "from transformers import AutoTokenizer, AutoModelForSequenceClassification\n",
        "import numpy as np\n",
        "\n",
        "\n",
        "\n",
        "#close to zero is the AI generated text\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "detector_tokenizer = AutoTokenizer.from_pretrained(\"tommyliphys/ai-detector-distilbert\")\n",
        "detector_tokenizer.add_special_tokens({'pad_token': '[PAD]'})\n",
        "\n",
        "detector_model = AutoModelForSequenceClassification.from_pretrained(\"tommyliphys/ai-detector-distilbert\", from_tf=True)\n",
        "detector_model.to(device)\n",
        "\n",
        "def rate_content(content):\n",
        "\n",
        "    inputs = detector_tokenizer(content, return_tensors=\"pt\", padding=True,truncation=True, max_length=512).to(device)\n",
        "    with torch.no_grad():\n",
        "        outputs = detector_model(**inputs)\n",
        "        predictions = torch.softmax(outputs.logits, dim=-1)\n",
        "    ai_probability = predictions[0][1].item()\n",
        "    ai_probability = np.clip(ai_probability, 0.0, 1.0)\n",
        "    return ai_probability\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8fVU2i32Hfyr",
        "outputId": "8c972a6b-a7e4-417c-f9f3-a50888922d87"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "All TF 2.0 model weights were used when initializing DistilBertForSequenceClassification.\n",
            "\n",
            "All the weights of DistilBertForSequenceClassification were initialized from the TF 2.0 model.\n",
            "If your task is similar to the task the model of the checkpoint was trained on, you can already use DistilBertForSequenceClassification for predictions without further training.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(rate_content(\"\"\"The rise of Artificial Intelligence (AI) has revolutionized numerous industries, including education. AI-powered tools and software are being used to personalize learning, automate grading, and enhance student engagement. However, the impact of AI on the education system is a topic of ongoing debate.\n",
        "\n",
        "One of the most significant effects of AI on education is the ability to personalize learning. AI-powered tools can analyze individual student data, identifying strengths and weaknesses, and providing tailored learning pathways. This can lead to improved academic outcomes, as students are able to learn at their own pace and focus on areas where they need the most support.\n",
        "\n",
        "Another area where AI is making a significant impact is in the realm of adaptive assessment. AI-powered tools can automatically adjust the difficulty level of quizzes and tests based on individual student performance, ensuring that students are held accountable for their own learning. This can help to reduce the stress and anxiety associated with high-stakes testing.\n",
        "\n",
        "However, the use of AI in education also raises concerns about the potential for bias and discrimination. AI algorithms can perpetuate existing biases and prejudices, leading to unequal treatment of certain groups of students. For example, AI-powered tools may be biased towards students from certain socio-economic backgrounds, or those with certain cultural or linguistic backgrounds.\n",
        "\n",
        "Moreover, the use of AI in education also raises concerns about the potential for job displacement. As AI takes over more routine and repetitive tasks, it may lead to job losses for educators and other professionals who are not directly involved in AI development.\n",
        "\n",
        "Despite these concerns, the use of AI in education is also having a positive impact on student outcomes. AI-powered tools can help to identify areas where students need additional support, and provide targeted interventions to help them succeed. For example, AI-powered speech-to-text tools can help students with learning disabilities to communicate more effectively, and AI-powered language learning tools can help students to improve their language skills.\"\"\"))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dCJXIMuLLuS9",
        "outputId": "b0ccd922-6df2-4c1b-9a1c-057772862477"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0.9990649819374084\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import torch\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "from transformers import AdamW, AutoTokenizer, AutoModelForCausalLM\n",
        "from tqdm import tqdm\n",
        "\n",
        "# Load the model and tokenizer\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "model = AutoModelForCausalLM.from_pretrained(\"gpt2\").to(device)\n",
        "tokenizer = AutoTokenizer.from_pretrained(\"gpt2\")\n",
        "\n",
        "# Custom dataset class for balanced DataFrame\n",
        "class CustomDataset(Dataset):\n",
        "    def __init__(self, df):\n",
        "        self.df = df\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.df)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        row = self.df.iloc[idx]\n",
        "        return row['text'], row['generated']\n",
        "\n",
        "\"\"\"\"\n",
        "\n",
        "This model strongly rewards low ai_probability values (indicating low AI detectability) and scales down rewards as the AI probability increases.\n",
        "\n",
        "\"\"\"\"\n",
        "\n",
        "def compute_reward(text):\n",
        "    ai_probability = rate_content(text)\n",
        "    reward = 20 * np.exp(-5 * ai_probability)\n",
        "    reward = np.clip(reward, -10, 10)\n",
        "\n",
        "    return reward\n",
        "\n",
        "# Tokenization and reward function for batch\n",
        "def tokenize_and_get_rewards(batch):\n",
        "    texts, feedbacks = batch\n",
        "    tokenized_inputs = tokenizer(list(texts), return_tensors=\"pt\", padding=True, truncation=True, max_length=512).to(device)\n",
        "    rewards = torch.tensor([compute_reward(text) for text in texts], device=device)\n",
        "    return tokenized_inputs, rewards\n",
        "\n",
        "# DataLoader with collate function\n",
        "def collate_fn(batch):\n",
        "    texts, responses = zip(*batch)\n",
        "    return list(texts), list(responses)\n",
        "\n",
        "# Initialize DataLoader\n",
        "train_dataset = CustomDataset(balanced_dataset)\n",
        "train_dataloader = DataLoader(train_dataset, batch_size=8, collate_fn=collate_fn, shuffle=True)\n",
        "\n",
        "# Define the optimizer\n",
        "optimizer = AdamW(model.parameters(), lr=5e-5)\n",
        "\n",
        "# Reward normalization function\n",
        "@torch.no_grad()\n",
        "def whiten(values, shift_mean=True):\n",
        "    values = values.float()\n",
        "    mean, var = values.mean(), values.var(unbiased=False)\n",
        "    whitened = (values - mean) / torch.sqrt(var + 1e-8)\n",
        "    if not shift_mean:\n",
        "        whitened += mean\n",
        "    return whitened\n",
        "\n",
        "# PPO update function\n",
        "def ppo_update(states, actions, rewards, advantages, old_log_probs, epsilon_clip=0.2, beta=0.1):\n",
        "    outputs = model(**states, labels=actions)\n",
        "    new_log_probs = outputs.logits.log_softmax(-1).mean(-1).mean(-1)\n",
        "    old_log_probs = old_log_probs.to(device)\n",
        "\n",
        "    # KL penalty directly added to loss\n",
        "    kl_penalty = beta * (new_log_probs - old_log_probs).sum().mean()\n",
        "    ratios = (new_log_probs - old_log_probs).exp()\n",
        "    surr1 = ratios * advantages\n",
        "    surr2 = torch.clamp(ratios, 1 - epsilon_clip, 1 + epsilon_clip) * advantages\n",
        "    ppo_loss = -torch.min(surr1, surr2).mean()\n",
        "\n",
        "    loss = ppo_loss + kl_penalty\n",
        "\n",
        "    optimizer.zero_grad()\n",
        "    loss.backward()\n",
        "    optimizer.step()\n",
        "\n",
        "    return loss.item()\n",
        "\n",
        "# Training loop for PPO\n",
        "def train_ppo(epochs=2, epsilon_clip=0.2, beta=0.1):\n",
        "    model.train()\n",
        "    for epoch in range(epochs):\n",
        "        total_loss = 0\n",
        "        for batch in tqdm(train_dataloader, desc=f\"Epoch {epoch+1}/{epochs}\"):\n",
        "            tokenized_inputs, rewards = tokenize_and_get_rewards(batch)\n",
        "            rewards = whiten(rewards, shift_mean=False)\n",
        "\n",
        "            with torch.no_grad():\n",
        "                outputs = model(**tokenized_inputs)\n",
        "                log_probs = outputs.logits.log_softmax(-1).mean(-1).mean(-1)\n",
        "                values = log_probs.mean()\n",
        "\n",
        "            advantages = rewards - values\n",
        "            loss = ppo_update(tokenized_inputs, tokenized_inputs[\"input_ids\"], rewards, advantages, log_probs, epsilon_clip, beta)\n",
        "            total_loss += loss\n",
        "\n",
        "        print(f\"Epoch {epoch+1}/{epochs}, Average Loss: {total_loss / len(train_dataloader):.4f}\")\n",
        "\n",
        "    # Save the model and tokenizer\n",
        "    save_directory = \"ppo_model_tokenizer\"\n",
        "    model.save_pretrained(save_directory)\n",
        "    tokenizer.save_pretrained(save_directory)\n",
        "    print(\"Model and tokenizer saved successfully!\")\n",
        "\n",
        "# Example usage for training\n",
        "train_ppo(epochs=10)\n"
      ],
      "metadata": {
        "id": "JKRnDapDGHS4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Train PPO with reward normalization and adaptive KL penalty\n",
        "def train_ppo(epochs=2, epsilon_clip=0.2, beta=0.1):\n",
        "    model.train()\n",
        "    for epoch in range(epochs):\n",
        "        total_loss = 0\n",
        "        for batch in tqdm(train_dataloader, desc=f\"Epoch {epoch+1}/{epochs}\"):\n",
        "            tokenized_inputs, rewards = tokenize_and_get_rewards(batch)\n",
        "            tokenized_inputs = {k: v.to(device) for k, v in tokenized_inputs.items()}\n",
        "            rewards = rewards.to(device)\n",
        "\n",
        "            with torch.no_grad():\n",
        "                outputs = model(**tokenized_inputs)\n",
        "                log_probs = outputs.logits.log_softmax(-1)\n",
        "                values = log_probs.mean(-1).mean(-1)  # Average over sequence length and vocabulary\n",
        "\n",
        "            # Reward normalization\n",
        "            rewards = whiten(rewards, shift_mean=False)\n",
        "            advantages = rewards - values\n",
        "\n",
        "            loss = ppo_update(tokenized_inputs, tokenized_inputs[\"input_ids\"], rewards, advantages, log_probs, epsilon_clip, beta)\n",
        "            total_loss += loss\n",
        "\n",
        "        print(f\"Epoch {epoch+1}/{epochs}, Average Loss: {total_loss / len(train_dataloader):.4f}\")\n",
        "\n",
        "    # Save the model and tokenizer\n",
        "    save_directory = \"ppo_model_tokenizer\"\n",
        "    model.save_pretrained(save_directory)\n",
        "    tokenizer.save_pretrained(save_directory)\n",
        "    print(\"Model and tokenizer saved successfully!\")\n",
        "\n",
        "# Example usage for training\n",
        "train_ppo(epochs=10)"
      ],
      "metadata": {
        "id": "v4PMD-hSDRx_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Generate response example\n",
        "@torch.no_grad()\n",
        "def generate_response(input_text):\n",
        "    model.eval()\n",
        "    input_ids = tokenizer.encode(input_text, return_tensors='pt').to(device)\n",
        "    output_ids = model.generate(input_ids, max_length=400, num_return_sequences=1, do_sample=True, pad_token_id=tokenizer.pad_token_id)\n",
        "    return tokenizer.decode(output_ids[0], skip_special_tokens=True)\n",
        "\n",
        "response = generate_response(\"Explain the importance of forests.\")\n",
        "print(f\"Generated response: {response}\")"
      ],
      "metadata": {
        "id": "9UtKlK4xDQyk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "https://www.kaggle.com/datasets/sunilthite/llm-detect-ai-generated-text-dataset"
      ],
      "metadata": {
        "id": "evgldrDTAiAG"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}